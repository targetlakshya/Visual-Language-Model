{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":39911,"sourceType":"datasetVersion","datasetId":31296},{"sourceId":1431853,"sourceType":"datasetVersion","datasetId":838708}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nbase_dir= \"/kaggle/input/flickr-image-dataset/flickr30k_images/\"\ndataset = \"/kaggle/input/flickr-image-dataset/flickr30k_images/results.csv\"\nIMG_PATH = \"/kaggle/input/flickr-image-dataset/flickr30k_images/flickr30k_images/\"\n\n# shift + enter se run hoga ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-22T14:14:52.744464Z","iopub.execute_input":"2024-07-22T14:14:52.745497Z","iopub.status.idle":"2024-07-22T14:14:53.923357Z","shell.execute_reply.started":"2024-07-22T14:14:52.745451Z","shell.execute_reply":"2024-07-22T14:14:53.921154Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install --upgrade tensorflow_hub\nimport tensorflow_hub as hub","metadata":{"execution":{"iopub.status.busy":"2024-07-22T14:14:53.929094Z","iopub.execute_input":"2024-07-22T14:14:53.932400Z","iopub.status.idle":"2024-07-22T14:15:26.732803Z","shell.execute_reply.started":"2024-07-22T14:14:53.932162Z","shell.execute_reply":"2024-07-22T14:15:26.731587Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow_hub in /opt/conda/lib/python3.10/site-packages (0.16.1)\nRequirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_hub) (1.26.4)\nRequirement already satisfied: protobuf>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow_hub) (3.20.3)\nRequirement already satisfied: tf-keras>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow_hub) (2.15.1)\nRequirement already satisfied: tensorflow<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tf-keras>=2.14.1->tensorflow_hub) (2.15.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (0.2.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (21.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (1.60.0)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (2.15.0)\nCollecting keras<2.16,>=2.15.0 (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub)\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (2.32.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (3.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (3.1.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (2024.7.4)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (3.2.2)\nDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: keras\n  Attempting uninstall: keras\n    Found existing installation: keras 3.4.1\n    Uninstalling keras-3.4.1:\n      Successfully uninstalled keras-3.4.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.15.0\n","output_type":"stream"},{"name":"stderr","text":"2024-07-22 14:15:14.467459: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-22 14:15:14.467594: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-22 14:15:14.626111: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nimport tensorflow_text\n","metadata":{"execution":{"iopub.status.busy":"2024-07-22T14:15:26.734372Z","iopub.execute_input":"2024-07-22T14:15:26.735009Z","iopub.status.idle":"2024-07-22T14:15:27.220290Z","shell.execute_reply.started":"2024-07-22T14:15:26.734978Z","shell.execute_reply":"2024-07-22T14:15:27.219314Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"print(dataset)","metadata":{"execution":{"iopub.status.busy":"2024-07-22T14:15:27.223553Z","iopub.execute_input":"2024-07-22T14:15:27.224488Z","iopub.status.idle":"2024-07-22T14:15:27.229645Z","shell.execute_reply.started":"2024-07-22T14:15:27.224444Z","shell.execute_reply":"2024-07-22T14:15:27.228383Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/input/flickr-image-dataset/flickr30k_images/results.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"df=pd.read_csv(dataset, delimiter='|')","metadata":{"execution":{"iopub.status.busy":"2024-07-22T14:15:27.231105Z","iopub.execute_input":"2024-07-22T14:15:27.231972Z","iopub.status.idle":"2024-07-22T14:15:27.799928Z","shell.execute_reply.started":"2024-07-22T14:15:27.231936Z","shell.execute_reply":"2024-07-22T14:15:27.798876Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm, tqdm_notebook\ntqdm.pandas()","metadata":{"execution":{"iopub.status.busy":"2024-07-22T14:15:27.801317Z","iopub.execute_input":"2024-07-22T14:15:27.801660Z","iopub.status.idle":"2024-07-22T14:15:27.807113Z","shell.execute_reply.started":"2024-07-22T14:15:27.801631Z","shell.execute_reply":"2024-07-22T14:15:27.805866Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df.columns\ndf.fillna","metadata":{"execution":{"iopub.status.busy":"2024-07-22T14:15:27.808724Z","iopub.execute_input":"2024-07-22T14:15:27.809563Z","iopub.status.idle":"2024-07-22T14:15:27.833227Z","shell.execute_reply.started":"2024-07-22T14:15:27.809529Z","shell.execute_reply":"2024-07-22T14:15:27.832035Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<bound method NDFrame.fillna of             image_name  comment_number  \\\n0       1000092795.jpg               0   \n1       1000092795.jpg               1   \n2       1000092795.jpg               2   \n3       1000092795.jpg               3   \n4       1000092795.jpg               4   \n...                ...             ...   \n158910   998845445.jpg               0   \n158911   998845445.jpg               1   \n158912   998845445.jpg               2   \n158913   998845445.jpg               3   \n158914   998845445.jpg               4   \n\n                                                  comment  \n0        Two young guys with shaggy hair look at their...  \n1        Two young , White males are outside near many...  \n2        Two men in green shirts are standing in a yard .  \n3            A man in a blue shirt standing in a garden .  \n4                 Two friends enjoy time spent together .  \n...                                                   ...  \n158910   A man in shorts and a Hawaiian shirt leans ov...  \n158911   A young man hanging over the side of a boat ,...  \n158912   A man is leaning off of the side of a blue an...  \n158913   A man riding a small boat in a harbor , with ...  \n158914   A man on a moored blue and white boat with hi...  \n\n[158915 rows x 3 columns]>"},"metadata":{}}]},{"cell_type":"code","source":"img_name_train=[]\ncap_train=[]\nfor index, row in df.iterrows():\n    img_name_train.append(IMG_PATH+row['image_name'])\n    cap_train.append(str(row[' comment']))","metadata":{"execution":{"iopub.status.busy":"2024-07-22T14:15:27.834661Z","iopub.execute_input":"2024-07-22T14:15:27.835003Z","iopub.status.idle":"2024-07-22T14:15:37.264426Z","shell.execute_reply.started":"2024-07-22T14:15:27.834976Z","shell.execute_reply":"2024-07-22T14:15:37.263219Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"try:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2024-07-22T14:15:37.265983Z","iopub.execute_input":"2024-07-22T14:15:37.266526Z","iopub.status.idle":"2024-07-22T14:15:37.289205Z","shell.execute_reply.started":"2024-07-22T14:15:37.266486Z","shell.execute_reply":"2024-07-22T14:15:37.288195Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"REPLICAS:  1\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(img_name_train),len(cap_train))","metadata":{"execution":{"iopub.status.busy":"2024-07-22T14:15:37.294540Z","iopub.execute_input":"2024-07-22T14:15:37.294898Z","iopub.status.idle":"2024-07-22T14:15:37.305311Z","shell.execute_reply.started":"2024-07-22T14:15:37.294869Z","shell.execute_reply":"2024-07-22T14:15:37.304148Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"158915 158915\n","output_type":"stream"}]},{"cell_type":"code","source":"print(img_name_train[0],cap_train[0])","metadata":{"execution":{"iopub.status.busy":"2024-07-22T14:15:37.306622Z","iopub.execute_input":"2024-07-22T14:15:37.307042Z","iopub.status.idle":"2024-07-22T14:15:37.317175Z","shell.execute_reply.started":"2024-07-22T14:15:37.307006Z","shell.execute_reply":"2024-07-22T14:15:37.316060Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"/kaggle/input/flickr-image-dataset/flickr30k_images/flickr30k_images/1000092795.jpg  Two young guys with shaggy hair look at their hands while hanging out in the yard .\n","output_type":"stream"}]},{"cell_type":"code","source":"def normalization(embeds):\n    norms = np.linalg.norm(embeds, 2, axis=1, keepdims=True)\n    return embeds/norms\npreprocessor = hub.KerasLayer(\n    \"https://tfhub.dev/google/universal-sentence-encoder-cmlm/multilingual-preprocess/2\")\nencoder = hub.KerasLayer(\n    \"https://tfhub.dev/google/universal-sentence-encoder-cmlm/multilingual-base-br/1\")","metadata":{"execution":{"iopub.status.busy":"2024-07-22T14:15:37.318549Z","iopub.execute_input":"2024-07-22T14:15:37.318877Z","iopub.status.idle":"2024-07-22T14:17:28.567298Z","shell.execute_reply.started":"2024-07-22T14:15:37.318849Z","shell.execute_reply":"2024-07-22T14:17:28.566314Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE=5\ntarget_size=(128,128)\nembedding_dim=128","metadata":{"execution":{"iopub.status.busy":"2024-07-22T14:17:28.568803Z","iopub.execute_input":"2024-07-22T14:17:28.569242Z","iopub.status.idle":"2024-07-22T14:17:28.574815Z","shell.execute_reply.started":"2024-07-22T14:17:28.569204Z","shell.execute_reply":"2024-07-22T14:17:28.573657Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def decode_image(filename, label=None, image_size=(target_size[0],target_size[1])):\n    means = [0.485, 0.456, 0.406]\n    stds = [0.229, 0.224, 0.225]\n    \n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    \n    image = (tf.cast(image, tf.float32) / 255.0)\n    image = (image - means) / stds # for qubvel EfficientNet\n    \n    image = tf.image.resize(image, image_size)\n    \n    if label is None:\n        return image\n    else:\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2024-07-22T14:17:28.576492Z","iopub.execute_input":"2024-07-22T14:17:28.577250Z","iopub.status.idle":"2024-07-22T14:17:28.587311Z","shell.execute_reply.started":"2024-07-22T14:17:28.577207Z","shell.execute_reply":"2024-07-22T14:17:28.586199Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def data_augment(image, label=None):\n    image = tf.image.random_flip_left_right(image)\n    \n    if label is None:\n        return image\n    else:\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2024-07-22T14:17:28.588679Z","iopub.execute_input":"2024-07-22T14:17:28.589033Z","iopub.status.idle":"2024-07-22T14:17:28.600174Z","shell.execute_reply.started":"2024-07-22T14:17:28.589004Z","shell.execute_reply":"2024-07-22T14:17:28.598828Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def get_training_dataset():\n    train_dataset = (\n        tf.data.Dataset\n        .from_tensor_slices((img_name_train, cap_train))\n        .map(decode_image, num_parallel_calls=10)\n        .cache()\n        .map(data_augment, num_parallel_calls=10)\n        .repeat() # Maybe not repeat in custom training (so when and how??) <-- the current version is bug because it repeat indefinitely\n        .shuffle(BATCH_SIZE*8, reshuffle_each_iteration=True)\n        .batch(BATCH_SIZE, drop_remainder=False)\n        .prefetch(10)\n    )\n    return strategy.experimental_distribute_dataset(train_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-07-22T14:17:28.601668Z","iopub.execute_input":"2024-07-22T14:17:28.602107Z","iopub.status.idle":"2024-07-22T14:17:28.612760Z","shell.execute_reply.started":"2024-07-22T14:17:28.602074Z","shell.execute_reply":"2024-07-22T14:17:28.611619Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"imageEncoderLayer=hub.KerasLayer(\"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_m/feature_vector/2\",\n                   trainable=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-22T14:17:28.614172Z","iopub.execute_input":"2024-07-22T14:17:28.614659Z","iopub.status.idle":"2024-07-22T14:17:59.816139Z","shell.execute_reply.started":"2024-07-22T14:17:28.614619Z","shell.execute_reply":"2024-07-22T14:17:59.814994Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class VisionEncoder(tf.keras.layers.Layer):\n    def __init__(self):\n        super(VisionEncoder,self).__init__()\n        self.encoder=imageEncoderLayer\n        self.ds=tf.keras.layers.Dense(embedding_dim,activation=\"relu\")\n    def call(self, x):\n        x=self.encoder(x)\n        x=self.ds(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-07-22T14:17:59.817528Z","iopub.execute_input":"2024-07-22T14:17:59.817861Z","iopub.status.idle":"2024-07-22T14:17:59.827843Z","shell.execute_reply.started":"2024-07-22T14:17:59.817834Z","shell.execute_reply":"2024-07-22T14:17:59.826613Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"d = VisionEncoder()\nprint(d)","metadata":{"execution":{"iopub.status.busy":"2024-07-22T14:17:59.829593Z","iopub.execute_input":"2024-07-22T14:17:59.830083Z","iopub.status.idle":"2024-07-22T14:17:59.846839Z","shell.execute_reply.started":"2024-07-22T14:17:59.830000Z","shell.execute_reply":"2024-07-22T14:17:59.845752Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"<__main__.VisionEncoder object at 0x7d5825e5bf40>\n","output_type":"stream"}]},{"cell_type":"code","source":"class TextEncoder(tf.keras.layers.Layer):\n    def __init__(self,preprocessor,encoder):\n        super(TextEncoder,self).__init__()\n        self.preprocessor=preprocessor\n        self.encoder=encoder\n        self.ds=tf.keras.layers.Dense(embedding_dim,activation=\"relu\")\n    def call(self, x):\n        x=self.preprocessor(x)\n        x=self.encoder(x)['default']\n        x=normalization(x)\n        x=self.ds(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-07-22T14:17:59.848202Z","iopub.execute_input":"2024-07-22T14:17:59.848629Z","iopub.status.idle":"2024-07-22T14:17:59.861188Z","shell.execute_reply.started":"2024-07-22T14:17:59.848600Z","shell.execute_reply":"2024-07-22T14:17:59.859991Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"ds=get_training_dataset()","metadata":{"execution":{"iopub.status.busy":"2024-07-22T14:17:59.862647Z","iopub.execute_input":"2024-07-22T14:17:59.863007Z","iopub.status.idle":"2024-07-22T14:18:01.064052Z","shell.execute_reply.started":"2024-07-22T14:17:59.862979Z","shell.execute_reply":"2024-07-22T14:18:01.062893Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CrossAttention(tf.keras.layers.Layer):\n    def __init__(self):\n        super(CrossAttention, self).__init__()\n        self.query=tf.keras.layers.Dense(embedding_dim,activation=\"relu\")\n        self.key=tf.keras.layers.Dense(embedding_dim,activation=\"relu\")\n        self.value=tf.keras.layers.Dense(embedding_dim,activation=\"relu\")\n        self.outputs=tf.keras.layers.Dense(embedding_dim)\n\n    def call(self, inputs):\n        vision_inputs,text_inputs=inputs\n        query_inputs=self.query(vision_inputs)\n        key_inputs=self.key(text_inputs)\n        value_inputs=self.value(text_inputs)\n        attention_scores = tf.matmul(query_inputs,key_inputs, transpose_b=True)\n        attention_scores = tf.nn.tanh(attention_scores)\n        attention_weights = tf.nn.softmax(attention_scores, axis=-1)\n        attended = tf.matmul(attention_weights,value_inputs)\n        output = tf.concat([text_inputs,attended],axis=-1)\n        output=self.outputs(output)\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-07-22T14:18:01.065521Z","iopub.execute_input":"2024-07-22T14:18:01.065894Z","iopub.status.idle":"2024-07-22T14:18:01.075562Z","shell.execute_reply.started":"2024-07-22T14:18:01.065863Z","shell.execute_reply":"2024-07-22T14:18:01.074159Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"class CrossAttentionEncoder(tf.keras.Model):\n    def __init__(self,visionEncoder,textEncoder):\n        super(CrossAttentionEncoder,self).__init__()\n        self.visionEncoder=visionEncoder\n        self.textEncoder=textEncoder\n        self.cross_attention=CrossAttention()\n        self.cross_attention2=CrossAttention()\n        self.similarity=tf.keras.losses.CosineSimilarity(axis=1)\n    def call(self,inputs):\n        vision_input,text_input=inputs\n#         print(vision_input,text_input)\n        vision_input=self.visionEncoder(vision_input)\n        text_input=self.textEncoder(text_input)\n        output1=self.cross_attention((vision_input,text_input))\n        output2=self.cross_attention2((text_input,vision_input))\n        return output1,output2","metadata":{"execution":{"iopub.status.busy":"2024-07-22T14:18:01.076979Z","iopub.execute_input":"2024-07-22T14:18:01.077423Z","iopub.status.idle":"2024-07-22T14:18:01.095604Z","shell.execute_reply.started":"2024-07-22T14:18:01.077390Z","shell.execute_reply":"2024-07-22T14:18:01.094418Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-07-22T14:18:01.097060Z","iopub.execute_input":"2024-07-22T14:18:01.097451Z","iopub.status.idle":"2024-07-22T14:18:01.881715Z","shell.execute_reply.started":"2024-07-22T14:18:01.097419Z","shell.execute_reply":"2024-07-22T14:18:01.879802Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"# with strategy.scope():\ntextEncoder = TextEncoder(preprocessor,encoder)\nImageEncoder=VisionEncoder()\ntransformer=CrossAttentionEncoder(ImageEncoder,textEncoder)\noptimizer = tf.keras.optimizers.Adam(learning_rate=LR)\nloss_object = tf.keras.losses.CosineSimilarity()\n    ","metadata":{"execution":{"iopub.status.busy":"2024-07-22T14:18:01.883392Z","iopub.execute_input":"2024-07-22T14:18:01.883789Z","iopub.status.idle":"2024-07-22T14:18:02.545052Z","shell.execute_reply.started":"2024-07-22T14:18:01.883751Z","shell.execute_reply":"2024-07-22T14:18:02.543067Z"},"trusted":true},"execution_count":25,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[25], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m ImageEncoder\u001b[38;5;241m=\u001b[39mVisionEncoder()\n\u001b[1;32m      4\u001b[0m transformer\u001b[38;5;241m=\u001b[39mCrossAttentionEncoder(ImageEncoder,textEncoder)\n\u001b[0;32m----> 5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[43mLR\u001b[49m)\n\u001b[1;32m      6\u001b[0m loss_object \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mCosineSimilarity()\n","\u001b[0;31mNameError\u001b[0m: name 'LR' is not defined"],"ename":"NameError","evalue":"name 'LR' is not defined","output_type":"error"}]},{"cell_type":"code","source":"\ndef train_step(img_tensor, text):\n    loss=0\n    hidden=transformer.reset_states()\n    with tf.GradientTape() as tape:\n        emb_a, emb_b=transformer((img_tensor,text))\n        loss+=1-loss_object(emb_a,emb_b)\n    total_loss=loss\n    trainable_variables=transformer.trainable_variables\n    gradient=tape.gradient(loss,trainable_variables)\n    optimizer.apply_gradients(zip(gradient,trainable_variables))\n    return loss, total_loss\ndef distributed_train_step(inputs):\n    (images, labels) = inputs\n    loss = strategy.run(train_step, args=(images, labels))\n    return loss","metadata":{"execution":{"iopub.status.busy":"2024-07-22T14:18:02.546235Z","iopub.status.idle":"2024-07-22T14:18:02.546684Z","shell.execute_reply.started":"2024-07-22T14:18:02.546480Z","shell.execute_reply":"2024-07-22T14:18:02.546498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# with strategy.scope():\ncounter=0\ntotal_loss=0\nfor batch in ds:\n    if counter==1000:\n        break\n    counter+=1\n    _, t_loss=train_step(batch[0],batch[1])\n    total_loss+=t_loss\n    print ('Epoch {} Batch {} Loss {:.4f}'.format(1, counter, t_loss.numpy() ))\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2024-07-22T14:18:02.548827Z","iopub.status.idle":"2024-07-22T14:18:02.549378Z","shell.execute_reply.started":"2024-07-22T14:18:02.549093Z","shell.execute_reply":"2024-07-22T14:18:02.549114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_names=[decode_image('/kaggle/input/flickr-image-dataset/flickr30k_images/flickr30k_images/1000092795.jpg')]\ntext=['Shaggy hair hangs down, obscuring their hands as two young men share a quiet moment in the yard.']\na,b=transformer((file_names,text))\nprint(tf.keras.losses.CosineSimilarity()(a,b))\na,b=transformer((file_names,['.3']))\nprint(tf.keras.losses.CosineSimilarity()(a,b))","metadata":{"execution":{"iopub.status.busy":"2024-07-22T14:18:02.551230Z","iopub.status.idle":"2024-07-22T14:18:02.551798Z","shell.execute_reply.started":"2024-07-22T14:18:02.551532Z","shell.execute_reply":"2024-07-22T14:18:02.551556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}